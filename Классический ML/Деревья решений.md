## Критерий энтропии  
Энтропия - это мера определённости (в случае с деревьями решений). Абсолютная неопределённость и полная определённость соответственно 1 и 0  
$$E=-\sum_{i=1}^{n} p_i\cdot\log_2(p_i)$$  
В формуле выше n - это количество вариантов результата, а p - вероятность каждого из них. Например, данные, где 4 котика и 6 собачек:  
$$E=-\frac{4}{10}\cdot\log_2\frac{4}{10}-\frac{6}{10}\cdot\log_2\frac{6}{10}=0.971$$  
Суть метода состоит в том, что необходимо на каждую *"фичу"* (предиктор, переменная, столбик в data frame) последовательно вычислить их энтропии, разбить по этой фиче данные на *сплит*, в котором далее вычислять энтропии и разбивать данные на более мелкие, пока не будет достигнута нулевая энтропия на каждой ветке  
![Pasted image 20221124161328.png|450](https://github.com/PolkaDott/Data-Science-Summaries/blob/main/Машинное%20обучение/attachments/Pasted%20image%2020221124161328.png?raw=true)  
На каждом уровне вычисляется вычисляются энтропия для всех фичей и применяется самая маленькая  
Также есть понятие *Information Gain* - мера снижения неопределённости между сплитами. Нужно для оценки разбиения  
$$IG=E(Y)-E(Y/X)$$  
В формуле выше $E(Y)$ - это изначальная энтропия, а $E(Y/X)$ - энтропия при разбиении по фиче $X$  
Особенность метода в том, что он старается на каждом расщеплении получить максимальный прирост информации  
  
## Критерий неопределённости Джини  
В отличие от метода Энтропии, Джини пытается на каждом расщеплении максимизировать количество пар объектов одного класса, оказавшихся с одном поддереве, что видно из формулы  
$$G=1-\sum_k{p_k^2}$$  
На практике энтропия и неопределённость Джини дают примерно 2% разницу классификации  
  
## Понижение дисперсии  
Другие критерии опасны тем, что в них данные должны быть дискретезированы. Понижение дисперсии применяется в тех случаях, когда переменная непрерывна (дерево регрессии). Понижение дисперсии узла определяется как общее сокращение дисперсии целевой переменной  
  
### Кроссвалидация  
Глубина такого дерева может быть очень большой, что приведёт к переобучению модели. Чтобы избежать переобучения можно указать точную максимальную длину дерева. Для нахождения оптимальной длины можно разбить данные на *тестовые* и *тренировочные*. Вторыми модель тренировать, а первых она не видит до начала тестирования и на тестировании проверять корректность. Если учить модель 100 раз, чтобы глубина дерева была от 1 до 100, можно получить такой график:  
![Pasted image 20221124203249.png|400](https://github.com/PolkaDott/Data-Science-Summaries/blob/main/Машинное%20обучение/attachments/Pasted%20image%2020221124203249.png?raw=true)  
Видно, что *score* наилучший при глубине дерева примерно 4. Но такой тест **неправильный** и приводит к переобучению модели. Дело в том, что тренировочные данные могли идеально подойти конкретно под глубину дерева равную 4, а не глубина 4 под данные. Для этого используется *кроссвалидация*.   
![Pasted image 20221124203714.png|400](https://github.com/PolkaDott/Data-Science-Summaries/blob/main/Машинное%20обучение/attachments/Pasted%20image%2020221124203714.png?raw=true)  
На рисунке выше описана схема работы. Тренировочные данные пилятся ещё на, допустим, 5 кусков. Тогда на каждой из 5 итераций каждый кусок вынимается и модель обучается на остальных 4-х. Тот исключённый кусок является тестовым и на нём проверяется точность модели. Получается пять *точностей*, среднее из которых будет более корректным значением для оценки конкретной глубины дерева. Исправленный график ниже:  
![Pasted image 20221124204523.png|400](https://github.com/PolkaDott/Data-Science-Summaries/blob/main/Машинное%20обучение/attachments/Pasted%20image%2020221124204523.png?raw=true)  
Из него видно, что глубина 4 на самом деле является не самой лучшей по усреднённым тестам  
  
Есть много способов разделения данных для кроссвалидации. *ShuffleSplit*, *LeaveOneOut*, *LeavePOut*, *StratifiedKFold*... Какую использовать - нужно подбирать в зависимости от параметров выборки. Чаще при упоминании имеют ввиду K-Fold, который и представлен на картинке  
  
### Метрики  
Если просто, Precision - "главное не пропустить",   
Recall - "главное не потерять"  
F score - это оценка сразу обоих параметров  
$$Precision=\frac{TP}{TP+FP}$$  
$$Recall=\frac{TP}{TP+FN}$$  
$$F score=\frac{2\cdot(Precision\cdot Recall)}{Precision+Recall}$$  
Это самые основные, их куда больше  
  
### Стрижка деревьев  
В борьбе с переобучением может помочь не только искусственное ограничение глубины, размера сплита или сэмплов в листе, но и стрижка уже построенных переобученных деревьев. На каждой итерации отсекается узел, затем сравнивается общая предсказательная способность модели, из чего принимается решение об удалении листа