В неком n-мерном пространстве выбираются соседние к точке наблюдения и по их принадлежности принимается решение о классификации этой точки  
![Pasted image 20221130010525.png|400](https://github.com/PolkaDott/Data-Science-Summaries/blob/main/Классический%20ML/attachments/Pasted%20image%2020221130010525.png?raw=true)  
Метод может использоваться также и для задач регрессии.  
Для классификации алгоритм такой:  
- Вычислить расстояние до каждого из объектов  
- Выбрать $k$ объектов с минимальным расстоянием  
- Класс исследуемого объекта выбирается по самому частому классу среди отобранных $k$ наблюдений  
Для задач регрессии на третьем этапе возвращается среднее значение целевого признака среди соседей  
  
> Достоинство метода в том, что его не нужно обучать, правда во время классификации огромные выборки могут быть проблемой, поэтому иногда используют какие-нибудь приближённые методы  
  
> Считается, что при "бесконечных" выборках этот метод является оптимальным  
  
Параметры:  
- число соседей  
- метрика расстояния между объектами. Часто используется метрика Хэмминга, евклидово расстояние, косинусное расстояние, расстояние Минковского. Но нужно масштабировать данные (зп 100к и возраст 80 лет)  
- веса соседей  
