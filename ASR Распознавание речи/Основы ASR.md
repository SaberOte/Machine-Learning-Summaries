Для задач распознавания речи, аудиопоток делят на **фреймы**. Обычно фреймы длятся по 10 мс, а друг за другом идут *внахлёст*, чтобы сгладить результаты анализа фреймов (размазать). Обычно нахлёст составляет 50%. Примерно, одно слово в среднем занимает 500 мс.   
Первая задача для распознавания - это разбивание аудиодорожки на раздельные слова. Самый простой способ - это разбивать слова, используя *энтропию* (можно сказать, мера беспорядка). Если же энтропия в фрейме сильне ниже среднего значения, то, возможно, в нём фиксируется тишина, что означает речевую паузу между словами. На практике такой подход вызывает ложные срабатывания, поэтому есть некоторые ухищрения по типу введения минимальной длины слова и склеивания фреймов.  
  
## Классических подход  
На картинке изображен базовый Pipeline **КЛАССИЧЕСКОГО** подхода к распознаванию речи  
![Pasted image 20230424015958.png](https://github.com/PolkaDott/Data-Science-Summaries/blob/main/ASR%20Распознавание%20речи/attachments/Pasted%20image%2020230424015958.png?raw=true)  
  
На этапе **Feature Extraction** используется например MFCC:  
#### MFCC (Мел-частотные кепстральные коэффициенты)  
Эти *коэффициенты* часто используются в качестве характеристики речевых сигналов.  
**Мел** - единица высоты звука, основанная на восприятии этого звука органами слуха.  
После ряда преобразований, на выход извлекается набор коэффициентов, который представляет собой последовательность векторов фиксированной длины для каждого кадра. Обычно используют первые 13 вычисленных, но это варьируется.   
  
Следующий компонент - **acoustic model**. Может быть основана на глубоких нейронных сетях (DNN на рис.) либо же на ~~устаревших~~ классических гауссовых распределений и скрытых макровских моделях (HMM). Главное на этом этапе выделение на фреймах распределения вероятностей различных **фонем**.  
  
## End2End подход  
